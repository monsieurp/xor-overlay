From a367c4a749ba76526f1a78ab48281e5864ec78de Mon Sep 17 00:00:00 2001
From: Kris Van Hees <kris.van.hees@oracle.com>
Date: Mon, 19 Nov 2018 19:02:39 +0000
Subject: [PATCH 14/24] dtrace: function boundary tracing (FBT) core and x86
 components

This commit implements the core components needed for FBT tracing.
Unlike ftrace we allow the tracing of very large numbers of functions at
once: the intent is that the system should still be stable when every
eligible function in the kernel is traced simultaneously.  Functions
that are not safe for this (because e.g. they are used in trap handling,
or by functions called by the DTrace module itself during probe
processing) are (semi-manually) blacklisted from being probed.

As part of this, a treewide change to the prototype of traps is started:
they all return 0 by default now, with a nonzero return value indicating
that the trap happened as a result of an FBT probe: the return value is
the opcode atop which the trap was originally placed for later emulation.

Signed-off-by: Kris Van Hees <kris.van.hees@oracle.com>
Signed-off-by: Tomas Jedlicka <tomas.jedlicka@oracle.com>
Signed-off-by: Nick Alcock <nick.alcock@oracle.com>
Signed-off-by: Eugene Loh <eugene.loh@oracle.com>
Signed-off-by: David Mc Lean <david.mclean@oracle.com>
Signed-off-by: Vincent Lim <vincent.lim@oracle.com>
---
 arch/x86/entry/entry_64.S       | 157 +++++++++++++++++++++++++++-
 arch/x86/include/asm/kvm_para.h |   2 +-
 arch/x86/include/asm/mce.h      |   4 +-
 arch/x86/include/asm/traps.h    |  44 ++++----
 arch/x86/kernel/cpu/mce/core.c  |  14 +--
 arch/x86/kernel/dtrace_fbt.c    | 177 ++++++++++++++++++++++++++++++++
 arch/x86/kernel/fbt_blacklist.h |  92 +++++++++++++++++
 arch/x86/kernel/kvm.c           |   4 +-
 arch/x86/kernel/nmi.c           |   5 +-
 arch/x86/kernel/traps.c         |  83 +++++++++------
 arch/x86/mm/fault.c             |  10 +-
 include/linux/dtrace_fbt.h      |  48 +++++++++
 kernel/dtrace/Kconfig           |   7 ++
 kernel/dtrace/Makefile          |   4 +-
 kernel/dtrace/dtrace_fbt_core.c | 125 ++++++++++++++++++++++
 kernel/dtrace/dtrace_os.c       |   2 +
 kernel/kprobes.c                |   8 ++
 17 files changed, 716 insertions(+), 70 deletions(-)
 create mode 100644 arch/x86/kernel/dtrace_fbt.c
 create mode 100644 arch/x86/kernel/fbt_blacklist.h
 create mode 100644 include/linux/dtrace_fbt.h
 create mode 100644 kernel/dtrace/dtrace_fbt_core.c

diff --git a/arch/x86/entry/entry_64.S b/arch/x86/entry/entry_64.S
index b7c3ea4cb19d..4f520830712a 100644
--- a/arch/x86/entry/entry_64.S
+++ b/arch/x86/entry/entry_64.S
@@ -38,6 +38,7 @@
 #include <asm/export.h>
 #include <asm/frame.h>
 #include <asm/nospec-branch.h>
+#include <asm/dtrace_util.h>
 #include <linux/err.h>
 
 #include "calling.h"
@@ -866,7 +867,7 @@ apicinterrupt IRQ_WORK_VECTOR			irq_work_interrupt		smp_irq_work_interrupt
  */
 #define CPU_TSS_IST(x) PER_CPU_VAR(cpu_tss_rw) + (TSS_ist + (x) * 8)
 
-.macro idtentry_part do_sym, has_error_code:req, read_cr2:req, paranoid:req, shift_ist=-1, ist_offset=0
+.macro idtentry_part do_sym, has_error_code:req, read_cr2:req, paranoid:req, shift_ist=-1, ist_offset=0, switch_stack=0
 
 	.if \paranoid
 	call	paranoid_entry
@@ -921,6 +922,13 @@ apicinterrupt IRQ_WORK_VECTOR			irq_work_interrupt		smp_irq_work_interrupt
 	addq	$\ist_offset, CPU_TSS_IST(\shift_ist)
 	.endif
 
+#ifdef CONFIG_DTRACE
+	.if \switch_stack == 0
+	test %rax,%rax
+	jnz dtrace_error_exit
+	.endif
+#endif
+
 	.if \paranoid
 	/* this procedure expect "no swapgs" flag in ebx */
 	jmp	paranoid_exit
@@ -1015,13 +1023,158 @@ ENTRY(\sym)
 	 * run in real process context if user_mode(regs).
 	 */
 .Lfrom_usermode_switch_stack_\@:
-	idtentry_part \do_sym, \has_error_code, \read_cr2, paranoid=0
+	idtentry_part \do_sym, \has_error_code, \read_cr2, paranoid=0, switch_stack=1
 	.endif
 
 _ASM_NOKPROBE(\sym)
 END(\sym)
 .endm
 
+#ifdef CONFIG_DTRACE
+ENTRY(dtrace_error_exit)
+	UNWIND_HINT_REGS
+	DISABLE_INTERRUPTS(CLBR_NONE)
+	TRACE_IRQS_OFF
+
+	/*
+	 * The iretq could re-enable interrupts:
+	 */
+	TRACE_IRQS_IRETQ
+
+	negq %rax
+
+	cmpl $DTRACE_INVOP_MOV_RSP_RBP,%eax
+	je dtrace_emu_mov
+	cmpl $DTRACE_INVOP_PUSH_BP,%eax
+	je dtrace_emu_push
+	cmpl $DTRACE_INVOP_LEAVE,%eax
+	je dtrace_emu_leave
+	cmpl $DTRACE_INVOP_NOP,%eax
+	je dtrace_emu_nop
+	cmpl $DTRACE_INVOP_RET,%eax
+	je dtrace_emu_ret
+
+	leaq dtrace_error_msg(%rip),%rdi
+	movq %rax,%rsi
+	movq (%rsp),%rdx
+	call printk
+
+	POP_REGS
+	addq	$8, %rsp	/* skip regs->orig_ax */
+	jmp dtrace_retint_kernel
+
+dtrace_emu_mov:
+	POP_REGS
+	addq	$8, %rsp	/* skip regs->orig_ax */
+
+	/* Emulate "mov %rsp, %rbp" instruction. */
+	pushq %rax			/* push temp */
+	movq 8(%rsp),%rax		/* load calling RIP */
+	addq $3,%rax			/* increment over trapping instr */
+	movq %rax,8(%rsp)		/* store calling RIP */
+	movq 32(%rsp),%rbp		/* load %rsp into %rbp */
+	popq %rax			/* pop off temp */
+
+	jmp dtrace_retint_kernel
+
+dtrace_emu_push:
+	POP_REGS
+	addq	$8, %rsp	/* skip regs->orig_ax */
+
+	/*
+	 * Emulate a "pushq %rbp" instruction.  We need to move the stack down
+	 * to make room for the extra address getting pushed.
+	 */
+	subq $16,%rsp			/* make room for %rbp */
+	pushq %rax			/* push temp */
+	movq 24(%rsp),%rax		/* load calling RIP */
+	addq $1,%rax			/* increment over trapping instr */
+	movq %rax,8(%rsp)		/* store calling RIP */
+	movq 32(%rsp),%rax		/* load calling CS */
+	movq %rax,16(%rsp)		/* store calling CS */
+	movq 40(%rsp),%rax		/* load calling RFLAGS */
+	movq %rax,24(%rsp)		/* store calling RFLAGS */
+	movq 48(%rsp),%rax		/* load calling RSP */
+	subq $8,%rax			/* make room for %rbp */
+	movq %rax,32(%rsp)		/* store calling RSP */
+	movq 56(%rsp),%rax		/* load calling SS */
+	movq %rax,40(%rsp)		/* store calling SS */
+	movq 32(%rsp),%rax		/* reload calling RSP */
+	movq %rbp,(%rax)		/* store %rbp there */
+	popq %rax			/* pop off temp */
+
+	jmp dtrace_retint_kernel
+
+dtrace_emu_nop:
+	POP_REGS
+	addq	$8, %rsp	/* skip regs->orig_ax */
+
+	/* Emulate a "nop" instruction. */
+	incq (%rsp)
+
+	jmp dtrace_retint_kernel
+
+dtrace_emu_leave:
+	POP_REGS
+	addq	$8, %rsp	/* skip regs->orig_ax */
+
+	/*
+	 * Emulate a "leave" instruction.  This is equivalent to the sequence:
+	 *	movq %rbp,%rsp
+	 *	popq %rbp
+	 * We can use the fact that on x86_64 %rsp is saved explicitly, so we
+	 * do not need to move any data around.
+	 */
+	pushq %rax			/* push temp */
+	movq 8(%rsp),%rax		/* load calling RIP */
+	addq $1,%rax			/* increment over trapping instr */
+	movq %rax,8(%rsp)		/* store calling RIP */
+	movq (%rbp),%rax		/* get new %rbp */
+	addq $8,%rbp			/* adjust new %rsp */
+	movq %rbp,32(%rsp)		/* store new %rsp */
+	movq %rax,%rbp			/* set new %rbp */
+	popq %rax			/* pop off temp */
+
+	jmp dtrace_retint_kernel
+
+dtrace_emu_ret:
+	POP_REGS
+	addq	$8, %rsp	/* skip regs->orig_ax */
+
+	/* Emulate a "ret" instruction. */
+	pushq %rax			/* push temp */
+	movq 32(%rsp),%rax		/* load %rsp */
+	movq (%rax),%rax		/* load calling RIP */
+	movq %rax,8(%rsp)		/* store calling RIP */
+	addq $8,32(%rsp)		/* adjust new %rsp */
+	popq %rax			/* pop off temp */
+
+	/* fallthrough */
+
+dtrace_retint_kernel:
+
+#ifdef CONFIG_PREEMPT
+	/* Interrupts are off */
+	/* Check if we need preemption */
+	bt      $9,2*8(%rsp) /* interrupts were off? (EFLAGS) */
+	jnc     1f
+0:      cmpl    $0,PER_CPU_VAR(__preempt_count)
+	jnz     1f
+	call    preempt_schedule_irq
+	jmp     0b
+1:
+#endif
+
+	INTERRUPT_RETURN
+
+END(dtrace_error_exit)
+
+.pushsection .rodata, "a"
+dtrace_error_msg:
+	.asciz "DTRACE: non-zero (%x) return from trap at %x\n"
+.popsection
+#endif
+
 idtentry divide_error			do_divide_error			has_error_code=0
 idtentry overflow			do_overflow			has_error_code=0
 idtentry bounds				do_bounds			has_error_code=0
diff --git a/arch/x86/include/asm/kvm_para.h b/arch/x86/include/asm/kvm_para.h
index 9b4df6eaa11a..45ceffca6737 100644
--- a/arch/x86/include/asm/kvm_para.h
+++ b/arch/x86/include/asm/kvm_para.h
@@ -92,7 +92,7 @@ void kvm_async_pf_task_wait(u32 token, int interrupt_kernel);
 void kvm_async_pf_task_wake(u32 token);
 u32 kvm_read_and_reset_pf_reason(void);
 extern void kvm_disable_steal_time(void);
-void do_async_page_fault(struct pt_regs *regs, unsigned long error_code, unsigned long address);
+int do_async_page_fault(struct pt_regs *regs, unsigned long error_code, unsigned long address);
 
 #ifdef CONFIG_PARAVIRT_SPINLOCKS
 void __init kvm_spinlock_init(void);
diff --git a/arch/x86/include/asm/mce.h b/arch/x86/include/asm/mce.h
index dc2d4b206ab7..24455ef64c95 100644
--- a/arch/x86/include/asm/mce.h
+++ b/arch/x86/include/asm/mce.h
@@ -240,8 +240,8 @@ extern void mce_disable_bank(int bank);
  */
 
 /* Call the installed machine check handler for this CPU setup. */
-extern void (*machine_check_vector)(struct pt_regs *, long error_code);
-void do_machine_check(struct pt_regs *, long);
+extern int (*machine_check_vector)(struct pt_regs *, long error_code);
+int do_machine_check(struct pt_regs *, long);
 
 /*
  * Threshold handler
diff --git a/arch/x86/include/asm/traps.h b/arch/x86/include/asm/traps.h
index b25e633033c3..af900ee18df7 100644
--- a/arch/x86/include/asm/traps.h
+++ b/arch/x86/include/asm/traps.h
@@ -61,38 +61,38 @@ asmlinkage void xen_machine_check(void);
 asmlinkage void xen_simd_coprocessor_error(void);
 #endif
 
-dotraplinkage void do_divide_error(struct pt_regs *regs, long error_code);
-dotraplinkage void do_debug(struct pt_regs *regs, long error_code);
-dotraplinkage void do_nmi(struct pt_regs *regs, long error_code);
-dotraplinkage void do_int3(struct pt_regs *regs, long error_code);
-dotraplinkage void do_overflow(struct pt_regs *regs, long error_code);
-dotraplinkage void do_bounds(struct pt_regs *regs, long error_code);
-dotraplinkage void do_invalid_op(struct pt_regs *regs, long error_code);
-dotraplinkage void do_device_not_available(struct pt_regs *regs, long error_code);
-dotraplinkage void do_coprocessor_segment_overrun(struct pt_regs *regs, long error_code);
-dotraplinkage void do_invalid_TSS(struct pt_regs *regs, long error_code);
-dotraplinkage void do_segment_not_present(struct pt_regs *regs, long error_code);
-dotraplinkage void do_stack_segment(struct pt_regs *regs, long error_code);
+dotraplinkage int do_divide_error(struct pt_regs *regs, long error_code);
+dotraplinkage int do_debug(struct pt_regs *regs, long error_code);
+dotraplinkage int do_nmi(struct pt_regs *regs, long error_code);
+dotraplinkage int do_int3(struct pt_regs *regs, long error_code);
+dotraplinkage int do_overflow(struct pt_regs *regs, long error_code);
+dotraplinkage int do_bounds(struct pt_regs *regs, long error_code);
+dotraplinkage int do_invalid_op(struct pt_regs *regs, long error_code);
+dotraplinkage int do_device_not_available(struct pt_regs *regs, long error_code);
+dotraplinkage int do_coprocessor_segment_overrun(struct pt_regs *regs, long error_code);
+dotraplinkage int do_invalid_TSS(struct pt_regs *regs, long error_code);
+dotraplinkage int do_segment_not_present(struct pt_regs *regs, long error_code);
+dotraplinkage int do_stack_segment(struct pt_regs *regs, long error_code);
 #ifdef CONFIG_X86_64
-dotraplinkage void do_double_fault(struct pt_regs *regs, long error_code, unsigned long address);
+dotraplinkage int do_double_fault(struct pt_regs *regs, long error_code, unsigned long address);
 asmlinkage __visible notrace struct pt_regs *sync_regs(struct pt_regs *eregs);
 asmlinkage __visible notrace
 struct bad_iret_stack *fixup_bad_iret(struct bad_iret_stack *s);
 void __init trap_init(void);
 #endif
-dotraplinkage void do_general_protection(struct pt_regs *regs, long error_code);
-dotraplinkage void do_page_fault(struct pt_regs *regs, unsigned long error_code, unsigned long address);
-dotraplinkage void do_spurious_interrupt_bug(struct pt_regs *regs, long error_code);
-dotraplinkage void do_coprocessor_error(struct pt_regs *regs, long error_code);
-dotraplinkage void do_alignment_check(struct pt_regs *regs, long error_code);
+dotraplinkage int do_general_protection(struct pt_regs *regs, long error_code);
+dotraplinkage int do_page_fault(struct pt_regs *regs, unsigned long error_code, unsigned long address);
+dotraplinkage int do_spurious_interrupt_bug(struct pt_regs *regs, long error_code);
+dotraplinkage int do_coprocessor_error(struct pt_regs *regs, long error_code);
+dotraplinkage int do_alignment_check(struct pt_regs *regs, long error_code);
 #ifdef CONFIG_X86_MCE
-dotraplinkage void do_machine_check(struct pt_regs *regs, long error_code);
+dotraplinkage int do_machine_check(struct pt_regs *regs, long error_code);
 #endif
-dotraplinkage void do_simd_coprocessor_error(struct pt_regs *regs, long error_code);
+dotraplinkage int do_simd_coprocessor_error(struct pt_regs *regs, long error_code);
 #ifdef CONFIG_X86_32
-dotraplinkage void do_iret_error(struct pt_regs *regs, long error_code);
+dotraplinkage int do_iret_error(struct pt_regs *regs, long error_code);
 #endif
-dotraplinkage void do_mce(struct pt_regs *regs, long error_code);
+dotraplinkage int do_mce(struct pt_regs *regs, long error_code);
 
 static inline int get_si_code(unsigned long condition)
 {
diff --git a/arch/x86/kernel/cpu/mce/core.c b/arch/x86/kernel/cpu/mce/core.c
index 743370ee4983..925048b98d02 100644
--- a/arch/x86/kernel/cpu/mce/core.c
+++ b/arch/x86/kernel/cpu/mce/core.c
@@ -1215,7 +1215,7 @@ static void __mc_scan_banks(struct mce *m, struct mce *final,
  * MCE broadcast. However some CPUs might be broken beyond repair,
  * so be always careful when synchronizing with others.
  */
-void do_machine_check(struct pt_regs *regs, long error_code)
+int do_machine_check(struct pt_regs *regs, long error_code)
 {
 	DECLARE_BITMAP(valid_banks, MAX_NR_BANKS);
 	DECLARE_BITMAP(toclear, MAX_NR_BANKS);
@@ -1250,7 +1250,7 @@ void do_machine_check(struct pt_regs *regs, long error_code)
 	int lmce = 1;
 
 	if (__mc_check_crashing_cpu(cpu))
-		return;
+		return 0;
 
 	ist_enter(regs);
 
@@ -1358,6 +1358,7 @@ void do_machine_check(struct pt_regs *regs, long error_code)
 
 out_ist:
 	ist_exit(regs);
+	return 0;
 }
 EXPORT_SYMBOL_GPL(do_machine_check);
 
@@ -1832,19 +1833,20 @@ bool filter_mce(struct mce *m)
 }
 
 /* Handle unconfigured int18 (should never happen) */
-static void unexpected_machine_check(struct pt_regs *regs, long error_code)
+static int unexpected_machine_check(struct pt_regs *regs, long error_code)
 {
 	pr_err("CPU#%d: Unexpected int18 (Machine Check)\n",
 	       smp_processor_id());
+	return 0;
 }
 
 /* Call the installed machine check handler for this CPU setup. */
-void (*machine_check_vector)(struct pt_regs *, long error_code) =
+int (*machine_check_vector)(struct pt_regs *, long error_code) =
 						unexpected_machine_check;
 
-dotraplinkage void do_mce(struct pt_regs *regs, long error_code)
+dotraplinkage int do_mce(struct pt_regs *regs, long error_code)
 {
-	machine_check_vector(regs, error_code);
+	return machine_check_vector(regs, error_code);
 }
 
 /*
diff --git a/arch/x86/kernel/dtrace_fbt.c b/arch/x86/kernel/dtrace_fbt.c
new file mode 100644
index 000000000000..52ff3f49d101
--- /dev/null
+++ b/arch/x86/kernel/dtrace_fbt.c
@@ -0,0 +1,177 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * FILE:        dtrace_fbt.c
+ * DESCRIPTION: Dynamic Tracing: FBT registration code (arch-specific)
+ *
+ * Copyright (c) 2010, 2017, Oracle and/or its affiliates. All rights reserved.
+ */
+
+#include <linux/kernel.h>
+#include <linux/kallsyms.h>
+#include <linux/dtrace_os.h>
+#include <linux/dtrace_fbt.h>
+#include <linux/slab.h>
+#include <linux/sort.h>
+#include <asm/insn.h>
+#include <asm/sections.h>
+
+#define FBT_MOV_RSP_RBP_1	0x48
+#define FBT_MOV_RSP_RBP_2	0x89
+#define FBT_MOV_RSP_RBP_3	0xe5
+#define FBT_PUSHL_EBP		0x55
+#define FBT_NOP			0x90
+#define FBT_RET_IMM16		0xc2
+#define FBT_RET			0xc3
+#define FBT_LEAVE		0xc9
+
+#define BL_SENTRY(tp, nm)	extern tp nm;
+#define BL_DENTRY(tp, nm)
+#include "fbt_blacklist.h"
+#undef BL_DENTRY
+#undef BL_SENTRY
+
+static void
+dtrace_fbt_populate_bl(void)
+{
+#define	BL_SENTRY(tp, nm)	dtrace_fbt_bl_add((unsigned long)&nm, \
+						  __stringify(nm));
+#define BL_DENTRY(tp, nm)	dtrace_fbt_bl_add(0, __stringify(nm));
+#include "fbt_blacklist.h"
+#undef BL_SENTRY
+#undef BL_DENTRY
+}
+
+void dtrace_fbt_init(fbt_add_probe_fn fbt_add_probe, struct module *mp,
+		     void *arg)
+{
+	loff_t			pos;
+	struct kallsym_iter	sym;
+	asm_instr_t		*paddr = NULL;
+	struct dt_fbt_bl_entry	*blent = NULL;
+
+	/*
+	 * Look up any unresolved symbols in the blacklist, and sort the list
+	 * by ascending address.
+	 */
+	dtrace_fbt_populate_bl();
+	blent = dtrace_fbt_bl_first();
+
+	pos = 0;
+	kallsyms_iter_reset(&sym, 0);
+	while (kallsyms_iter_update(&sym, pos++)) {
+		asm_instr_t	*addr, *end;
+		int		state = 0, insc = 0;
+		void		*fbtp = NULL;
+
+		/*
+		 * There is no point considering non-function symbols for FBT,
+		 * or symbols that have a zero size.  We could consider weak
+		 * symbols but that gets quite complicated and there is no
+		 * demands for that (so far).
+		 */
+		if (sym.type != 'T' && sym.type != 't')
+			continue;
+		if (!sym.size)
+			continue;
+
+		/*
+		 * Handle only symbols that belong to the module we have been
+		 * asked for.
+		 */
+		if (mp == dtrace_kmod && !core_kernel_text(sym.value))
+			continue;
+
+		/*
+		 * Ensure we have not been given .init symbol from kallsyms
+		 * interface. This could lead to memory corruption once DTrace
+		 * tries to enable probe in already freed memory.
+		 */
+		if (mp != dtrace_kmod && !within_module_core(sym.value, mp))
+			continue;
+
+		/*
+		 * See if the symbol is on the FBT's blacklist.  Since both
+		 * iterators are workng in sort order by ascending address we
+		 * can use concurrent traversal.
+		 */
+		while (blent != NULL &&
+		       dtrace_fbt_bl_entry_addr(blent) < sym.value) {
+			blent = dtrace_fbt_bl_next(blent);
+		}
+		if (dtrace_fbt_bl_entry_addr(blent) == sym.value)
+			continue;
+
+		/*
+		 * No FBT tracing for DTrace functions, and functions that are
+		 * crucial to probe processing.
+		 * Also weed out symbols that are not relevant here.
+		 */
+		if (strncmp(sym.name, "dtrace_", 7) == 0)
+			continue;
+		if (strncmp(sym.name, "insn_", 5) == 0)
+			continue;
+		if (strncmp(sym.name, "inat_", 5) == 0)
+			continue;
+		if (strncmp(sym.name, "_GLOBAL_", 8) == 0)
+			continue;
+		if (strncmp(sym.name, "do_", 3) == 0)
+			continue;
+		if (strncmp(sym.name, "xen_", 4) == 0)
+			continue;
+
+		addr = (asm_instr_t *)sym.value;
+		end = (asm_instr_t *)(sym.value + sym.size);
+
+		/*
+		 * FIXME:
+		 * When there are multiple symbols for the same address, we
+		 * should link them together as probes associated with the
+		 * same function.  When a probe for that function is triggered
+		 * all associated probes should fire.
+		 *
+		 * For now, we ignore duplicates.
+		 */
+		if (addr == paddr)
+			continue;
+		paddr = addr;
+
+		while (addr < end) {
+			struct insn	insn;
+
+			insc++;
+
+			switch (state) {
+			case 0:	/* start of function */
+				if (*addr == FBT_PUSHL_EBP) {
+					fbt_add_probe(
+						mp, sym.name,
+						FBT_ENTRY, *addr, addr, 0,
+						NULL, arg);
+					state = 1;
+				} else if (insc > 10)
+					state = 2;
+				break;
+			case 1: /* look for ret */
+				if (*addr == FBT_RET) {
+					uintptr_t	off;
+
+					off = addr - (asm_instr_t *)sym.value;
+					fbtp = fbt_add_probe(
+						mp, sym.name,
+						FBT_RETURN, *addr, addr, off,
+						fbtp, arg);
+				}
+				break;
+			}
+
+			if (state == 2)
+				break;
+
+			kernel_insn_init(&insn, addr, MAX_INSN_SIZE);
+			insn_get_length(&insn);
+
+			addr += insn.length;
+		}
+	}
+}
+EXPORT_SYMBOL(dtrace_fbt_init);
diff --git a/arch/x86/kernel/fbt_blacklist.h b/arch/x86/kernel/fbt_blacklist.h
new file mode 100644
index 000000000000..fd599859b47e
--- /dev/null
+++ b/arch/x86/kernel/fbt_blacklist.h
@@ -0,0 +1,92 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Functions used in die notifier chain calling.
+ */
+BL_SENTRY(void *, notify_die)
+BL_DENTRY(void *, notifier_call_chain)
+BL_SENTRY(typeof(__atomic_notifier_call_chain), __atomic_notifier_call_chain)
+BL_SENTRY(typeof(atomic_notifier_call_chain), atomic_notifier_call_chain)
+BL_SENTRY(typeof(__raw_notifier_call_chain), __raw_notifier_call_chain)
+BL_SENTRY(typeof(raw_notifier_call_chain), raw_notifier_call_chain)
+BL_DENTRY(void *, hw_breakpoint_exceptions_notify)
+BL_DENTRY(void *, kprobe_exceptions_notify)
+
+/*
+ * Functions used to update vtime in probe context.
+ */
+BL_SENTRY(typeof(ktime_get_raw_fast_ns), ktime_get_raw_fast_ns)
+BL_DENTRY(void *, raw_read_seqcount)
+BL_DENTRY(void *, read_seqcount_retry)
+BL_DENTRY(void *, __read_seqcount_retry)
+
+/* xen_clocksource */
+BL_DENTRY(void *, xen_clocksource_get_cycles)
+BL_DENTRY(void *, xen_clocksource_read)
+BL_DENTRY(void *, pvclock_clocksource_read)
+BL_DENTRY(void *, pvclock_touch_watchdogs)
+BL_DENTRY(void *, touch_softlockup_watchdog_sync)
+BL_DENTRY(void *, clocksource_touch_watchdog)
+BL_DENTRY(void *, clocksource_resume_watchdog)
+BL_DENTRY(void *, reset_hung_task_detector)
+/* clocksource_tsc */
+BL_DENTRY(void *, read_tsc)
+BL_DENTRY(void *, get_cycles)
+/* clocksource_hpet */
+BL_DENTRY(void *, read_hpet)
+BL_DENTRY(void *, hpet_readl)
+/* kvm_clock */
+BL_DENTRY(void *, kvm_clock_get_cycles)
+BL_DENTRY(void *, kvm_clock_read)
+
+/*
+ * Functions used in trap handling.
+ */
+BL_DENTRY(void *, fixup_exception)
+BL_DENTRY(void *, paranoid_entry)
+BL_DENTRY(void *, kgdb_ll_trap)
+BL_DENTRY(void *, error_entry)
+BL_DENTRY(void *, xen_int3)
+BL_DENTRY(void *, ftrace_int3_handler)
+BL_DENTRY(typeof(poke_int3_handler), poke_int3_handler)
+BL_DENTRY(void *, fixup_bad_iret)
+BL_DENTRY(void *, xen_adjust_exception_frame)
+BL_DENTRY(void *, paravirt_nop)
+BL_DENTRY(void *, ist_enter)
+BL_DENTRY(void *, rcu_nmi_enter)
+BL_DENTRY(void *, rcu_dynticks_curr_cpu_in_eqs)
+BL_DENTRY(void *, rcu_dynticks_eqs_exit)
+BL_DENTRY(void *, trace_rcu_dyntick)
+BL_DENTRY(void *, rcu_nmi_exit)
+BL_DENTRY(void *, rcu_dynticks_eqs_enter)
+BL_DENTRY(void *, ist_exit)
+
+/*
+ * Functions used in page fault handling.
+ */
+BL_SENTRY(void *, do_page_fault)
+BL_DENTRY(void *, __do_page_fault)
+BL_DENTRY(void *, huge_page_mask)
+BL_DENTRY(void *, mmap_address_hint_valid)
+BL_DENTRY(void *, vm_start_gap)
+BL_DENTRY(void *, hugetlb_get_unmapped_area_bottomup)
+BL_DENTRY(void *, hugetlb_get_unmapped_area_topdown)
+BL_DENTRY(void *, down_read_trylock)
+BL_DENTRY(void *, __get_user_pages_fast)
+BL_DENTRY(void *, gup_pud_range)
+BL_DENTRY(void *, gup_huge_pud)
+BL_DENTRY(void *, gup_pmd_range)
+BL_DENTRY(void *, gup_huge_pmd)
+BL_DENTRY(void *, gup_pte_range)
+BL_DENTRY(void *, pte_mfn_to_pfn)
+
+/*
+ * Functions used under 4.12 idr_find
+ */
+BL_DENTRY(void *, idr_find)
+BL_DENTRY(void *, find_next_bit)
+BL_DENTRY(void *, _find_next_bit)
+BL_DENTRY(void *, radix_tree_lookup)
+BL_DENTRY(void *, __radix_tree_lookup)
+BL_DENTRY(void *, radix_tree_load_root)
+BL_DENTRY(void *, radix_tree_descend)
+BL_DENTRY(void *, is_sibling_entry)
diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c
index e820568ed4d5..09742fc64c05 100644
--- a/arch/x86/kernel/kvm.c
+++ b/arch/x86/kernel/kvm.c
@@ -241,7 +241,7 @@ u32 kvm_read_and_reset_pf_reason(void)
 EXPORT_SYMBOL_GPL(kvm_read_and_reset_pf_reason);
 NOKPROBE_SYMBOL(kvm_read_and_reset_pf_reason);
 
-dotraplinkage void
+dotraplinkage int
 do_async_page_fault(struct pt_regs *regs, unsigned long error_code, unsigned long address)
 {
 	enum ctx_state prev_state;
@@ -262,6 +262,8 @@ do_async_page_fault(struct pt_regs *regs, unsigned long error_code, unsigned lon
 		rcu_irq_exit();
 		break;
 	}
+
+	return 0;
 }
 NOKPROBE_SYMBOL(do_async_page_fault);
 
diff --git a/arch/x86/kernel/nmi.c b/arch/x86/kernel/nmi.c
index e676a9916c49..bcbec09b35f5 100644
--- a/arch/x86/kernel/nmi.c
+++ b/arch/x86/kernel/nmi.c
@@ -509,7 +509,7 @@ static bool notrace is_debug_stack(unsigned long addr)
 NOKPROBE_SYMBOL(is_debug_stack);
 #endif
 
-dotraplinkage notrace void
+dotraplinkage notrace int
 do_nmi(struct pt_regs *regs, long error_code)
 {
 	if (IS_ENABLED(CONFIG_SMP) && cpu_is_offline(smp_processor_id()))
@@ -517,7 +517,7 @@ do_nmi(struct pt_regs *regs, long error_code)
 
 	if (this_cpu_read(nmi_state) != NMI_NOT_RUNNING) {
 		this_cpu_write(nmi_state, NMI_LATCHED);
-		return;
+		return 0;
 	}
 	this_cpu_write(nmi_state, NMI_EXECUTING);
 	this_cpu_write(nmi_cr2, read_cr2());
@@ -559,6 +559,7 @@ do_nmi(struct pt_regs *regs, long error_code)
 
 	if (user_mode(regs))
 		mds_user_clear_cpu_buffers();
+	return 0;
 }
 NOKPROBE_SYMBOL(do_nmi);
 
diff --git a/arch/x86/kernel/traps.c b/arch/x86/kernel/traps.c
index 4bb0f8447112..bd3a298a4500 100644
--- a/arch/x86/kernel/traps.c
+++ b/arch/x86/kernel/traps.c
@@ -260,9 +260,11 @@ do_trap(int trapnr, int signr, char *str, struct pt_regs *regs,
 }
 NOKPROBE_SYMBOL(do_trap);
 
-static void do_error_trap(struct pt_regs *regs, long error_code, char *str,
+static int do_error_trap(struct pt_regs *regs, long error_code, char *str,
 	unsigned long trapnr, int signr, int sicode, void __user *addr)
 {
+	int ret;
+
 	RCU_LOCKDEP_WARN(!rcu_is_watching(), "entry code didn't wake RCU");
 
 	/*
@@ -270,20 +272,21 @@ static void do_error_trap(struct pt_regs *regs, long error_code, char *str,
 	 * notifier chain.
 	 */
 	if (!user_mode(regs) && fixup_bug(regs, trapnr))
-		return;
+		return 0;
 
-	if (notify_die(DIE_TRAP, str, regs, error_code, trapnr, signr) !=
-			NOTIFY_STOP) {
+	ret = notify_die(DIE_TRAP, str, regs, error_code, trapnr, signr);
+	if ((ret & NOTIFY_STOP_MASK) != NOTIFY_STOP_MASK) {
 		cond_local_irq_enable(regs);
 		do_trap(trapnr, signr, str, regs, error_code, sicode, addr);
 	}
+	return notifier_to_errno(ret);
 }
 
 #define IP ((void __user *)uprobe_get_trap_addr(regs))
 #define DO_ERROR(trapnr, signr, sicode, addr, str, name)		   \
-dotraplinkage void do_##name(struct pt_regs *regs, long error_code)	   \
+dotraplinkage int do_##name(struct pt_regs *regs, long error_code)	   \
 {									   \
-	do_error_trap(regs, error_code, str, trapnr, signr, sicode, addr); \
+	return do_error_trap(regs, error_code, str, trapnr, signr, sicode, addr); \
 }
 
 DO_ERROR(X86_TRAP_DE,     SIGFPE,  FPE_INTDIV,   IP, "divide error",        divide_error)
@@ -313,7 +316,7 @@ __visible void __noreturn handle_stack_overflow(const char *message,
 
 #ifdef CONFIG_X86_64
 /* Runs on IST stack */
-dotraplinkage void do_double_fault(struct pt_regs *regs, long error_code, unsigned long cr2)
+dotraplinkage int do_double_fault(struct pt_regs *regs, long error_code, unsigned long cr2)
 {
 	static const char str[] = "double fault";
 	struct task_struct *tsk = current;
@@ -364,7 +367,7 @@ dotraplinkage void do_double_fault(struct pt_regs *regs, long error_code, unsign
 		regs->ip = (unsigned long)general_protection;
 		regs->sp = (unsigned long)&gpregs->orig_ax;
 
-		return;
+		return 0;
 	}
 #endif
 
@@ -425,17 +428,19 @@ dotraplinkage void do_double_fault(struct pt_regs *regs, long error_code, unsign
 	 */
 	for (;;)
 		die(str, regs, error_code);
+
+	return 0;
 }
 #endif
 
-dotraplinkage void do_bounds(struct pt_regs *regs, long error_code)
+dotraplinkage int do_bounds(struct pt_regs *regs, long error_code)
 {
 	const struct mpx_bndcsr *bndcsr;
 
 	RCU_LOCKDEP_WARN(!rcu_is_watching(), "entry code didn't wake RCU");
 	if (notify_die(DIE_TRAP, "bounds", regs, error_code,
 			X86_TRAP_BR, SIGSEGV) == NOTIFY_STOP)
-		return;
+		return 0;
 	cond_local_irq_enable(regs);
 
 	if (!user_mode(regs))
@@ -501,7 +506,7 @@ dotraplinkage void do_bounds(struct pt_regs *regs, long error_code)
 		die("bounds", regs, error_code);
 	}
 
-	return;
+	return 0;
 
 exit_trap:
 	/*
@@ -512,32 +517,34 @@ dotraplinkage void do_bounds(struct pt_regs *regs, long error_code)
 	 * time..
 	 */
 	do_trap(X86_TRAP_BR, SIGSEGV, "bounds", regs, error_code, 0, NULL);
+	return 0;
 }
 
-dotraplinkage void
+dotraplinkage int
 do_general_protection(struct pt_regs *regs, long error_code)
 {
 	const char *desc = "general protection fault";
 	struct task_struct *tsk;
+	int ret = 0;
 
 	RCU_LOCKDEP_WARN(!rcu_is_watching(), "entry code didn't wake RCU");
 	cond_local_irq_enable(regs);
 
 	if (static_cpu_has(X86_FEATURE_UMIP)) {
 		if (user_mode(regs) && fixup_umip_exception(regs))
-			return;
+			return 0;
 	}
 
 	if (v8086_mode(regs)) {
 		local_irq_enable();
 		handle_vm86_fault((struct kernel_vm86_regs *) regs, error_code);
-		return;
+		return 0;
 	}
 
 	tsk = current;
 	if (!user_mode(regs)) {
 		if (fixup_exception(regs, X86_TRAP_GP, error_code, 0))
-			return;
+			return 0;
 
 		tsk->thread.error_code = error_code;
 		tsk->thread.trap_nr = X86_TRAP_GP;
@@ -549,12 +556,13 @@ do_general_protection(struct pt_regs *regs, long error_code)
 		 */
 		if (!preemptible() && kprobe_running() &&
 		    kprobe_fault_handler(regs, X86_TRAP_GP))
-			return;
+			return 0;
 
-		if (notify_die(DIE_GPF, desc, regs, error_code,
-			       X86_TRAP_GP, SIGSEGV) != NOTIFY_STOP)
+		ret = notify_die(DIE_GPF, desc, regs, error_code,
+				 X86_TRAP_GP, SIGSEGV);
+		if ((ret & NOTIFY_STOP_MASK) != NOTIFY_STOP_MASK)
 			die(desc, regs, error_code);
-		return;
+		return notifier_to_errno(ret);
 	}
 
 	tsk->thread.error_code = error_code;
@@ -563,11 +571,13 @@ do_general_protection(struct pt_regs *regs, long error_code)
 	show_signal(tsk, SIGSEGV, "", desc, regs, error_code);
 
 	force_sig(SIGSEGV);
+	return 0;
 }
 NOKPROBE_SYMBOL(do_general_protection);
 
-dotraplinkage void notrace do_int3(struct pt_regs *regs, long error_code)
+dotraplinkage int notrace do_int3(struct pt_regs *regs, long error_code)
 {
+	int ret = 0;
 #ifdef CONFIG_DYNAMIC_FTRACE
 	/*
 	 * ftrace must be first, everything else may cause a recursive crash.
@@ -575,10 +585,10 @@ dotraplinkage void notrace do_int3(struct pt_regs *regs, long error_code)
 	 */
 	if (unlikely(atomic_read(&modifying_ftrace_code)) &&
 	    ftrace_int3_handler(regs))
-		return;
+		return 0;
 #endif
 	if (poke_int3_handler(regs))
-		return;
+		return 0;
 
 	/*
 	 * Use ist_enter despite the fact that we don't use an IST stack.
@@ -600,9 +610,13 @@ dotraplinkage void notrace do_int3(struct pt_regs *regs, long error_code)
 		goto exit;
 #endif
 
-	if (notify_die(DIE_INT3, "int3", regs, error_code, X86_TRAP_BP,
-			SIGTRAP) == NOTIFY_STOP)
+	ret = notify_die(DIE_INT3, "int3", regs, error_code, X86_TRAP_BP,
+			 SIGTRAP);
+	if ((ret & NOTIFY_STOP_MASK) == NOTIFY_STOP_MASK) {
+		ret = notifier_to_errno(ret);
 		goto exit;
+	} else
+		ret = 0;
 
 	cond_local_irq_enable(regs);
 	do_trap(X86_TRAP_BP, SIGTRAP, "int3", regs, error_code, 0, NULL);
@@ -610,6 +624,7 @@ dotraplinkage void notrace do_int3(struct pt_regs *regs, long error_code)
 
 exit:
 	ist_exit(regs);
+	return ret;
 }
 NOKPROBE_SYMBOL(do_int3);
 
@@ -706,7 +721,7 @@ static bool is_sysenter_singlestep(struct pt_regs *regs)
  *
  * May run on IST stack.
  */
-dotraplinkage void do_debug(struct pt_regs *regs, long error_code)
+dotraplinkage int do_debug(struct pt_regs *regs, long error_code)
 {
 	struct task_struct *tsk = current;
 	int user_icebp = 0;
@@ -807,6 +822,7 @@ dotraplinkage void do_debug(struct pt_regs *regs, long error_code)
 
 exit:
 	ist_exit(regs);
+	return 0;
 }
 NOKPROBE_SYMBOL(do_debug);
 
@@ -855,26 +871,29 @@ static void math_error(struct pt_regs *regs, int error_code, int trapnr)
 			(void __user *)uprobe_get_trap_addr(regs));
 }
 
-dotraplinkage void do_coprocessor_error(struct pt_regs *regs, long error_code)
+dotraplinkage int do_coprocessor_error(struct pt_regs *regs, long error_code)
 {
 	RCU_LOCKDEP_WARN(!rcu_is_watching(), "entry code didn't wake RCU");
 	math_error(regs, error_code, X86_TRAP_MF);
+	return 0;
 }
 
-dotraplinkage void
+dotraplinkage int
 do_simd_coprocessor_error(struct pt_regs *regs, long error_code)
 {
 	RCU_LOCKDEP_WARN(!rcu_is_watching(), "entry code didn't wake RCU");
 	math_error(regs, error_code, X86_TRAP_XF);
+	return 0;
 }
 
-dotraplinkage void
+dotraplinkage int
 do_spurious_interrupt_bug(struct pt_regs *regs, long error_code)
 {
 	cond_local_irq_enable(regs);
+	return 0;
 }
 
-dotraplinkage void
+dotraplinkage int
 do_device_not_available(struct pt_regs *regs, long error_code)
 {
 	unsigned long cr0 = read_cr0();
@@ -889,7 +908,7 @@ do_device_not_available(struct pt_regs *regs, long error_code)
 
 		info.regs = regs;
 		math_emulate(&info);
-		return;
+		return 0;
 	}
 #endif
 
@@ -905,11 +924,12 @@ do_device_not_available(struct pt_regs *regs, long error_code)
 		 */
 		die("unexpected #NM exception", regs, error_code);
 	}
+	return 0;
 }
 NOKPROBE_SYMBOL(do_device_not_available);
 
 #ifdef CONFIG_X86_32
-dotraplinkage void do_iret_error(struct pt_regs *regs, long error_code)
+dotraplinkage int do_iret_error(struct pt_regs *regs, long error_code)
 {
 	RCU_LOCKDEP_WARN(!rcu_is_watching(), "entry code didn't wake RCU");
 	local_irq_enable();
@@ -919,6 +939,7 @@ dotraplinkage void do_iret_error(struct pt_regs *regs, long error_code)
 		do_trap(X86_TRAP_IRET, SIGILL, "iret exception", regs, error_code,
 			ILL_BADSTK, (void __user *)NULL);
 	}
+	return 0;
 }
 #endif
 
diff --git a/arch/x86/mm/fault.c b/arch/x86/mm/fault.c
index ec68b3c4ef4b..6b84f85acd07 100644
--- a/arch/x86/mm/fault.c
+++ b/arch/x86/mm/fault.c
@@ -1546,7 +1546,14 @@ trace_page_fault_entries(struct pt_regs *regs, unsigned long error_code,
 		trace_page_fault_kernel(address, regs, error_code);
 }
 
-dotraplinkage void
+/*
+ * We must have this function blacklisted from kprobes, tagged with notrace
+ * and call read_cr2() before calling anything else. To avoid calling any
+ * kind of tracing machinery before we've observed the CR2 value.
+ *
+ * exception_{enter,exit}() contains all sorts of tracepoints.
+ */
+dotraplinkage int notrace
 do_page_fault(struct pt_regs *regs, unsigned long error_code, unsigned long address)
 {
 	enum ctx_state prev_state;
@@ -1555,5 +1562,6 @@ do_page_fault(struct pt_regs *regs, unsigned long error_code, unsigned long addr
 	trace_page_fault_entries(regs, error_code, address);
 	__do_page_fault(regs, error_code, address);
 	exception_exit(prev_state);
+	return 0;
 }
 NOKPROBE_SYMBOL(do_page_fault);
diff --git a/include/linux/dtrace_fbt.h b/include/linux/dtrace_fbt.h
new file mode 100644
index 000000000000..d11e273cee31
--- /dev/null
+++ b/include/linux/dtrace_fbt.h
@@ -0,0 +1,48 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ *Copyright (c) 2015, 2017, Oracle and/or its affiliates. All rights reserved.
+ */
+
+#ifndef _LINUX_DTRACE_FBT_H
+#define _LINUX_DTRACE_FBT_H
+
+#include <linux/module.h>
+#include <asm/dtrace_arch.h>
+
+extern unsigned long dtrace_fbt_nfuncs __attribute__((weak));
+
+/*
+ * Prototype for callback function that handles the actual creation of FBT
+ * probes.
+ *
+ * Arguments to pass:
+ *	- Pointer to module the probe will belong to
+ *	- function name
+ *	- probe type (FBT_ENTRY or FBT_RETURN)
+ *	- probe subtype (arch-specific)
+ *	- address (location of the probe)
+ *	- offset from the function start
+ *	- return value from previous callback invocation
+ *	- cookie passed to dtrace_fbt_init
+ * Returns:
+ *	- generic pointer (only to be used to pass back in)
+ */
+#define FBT_ENTRY	0
+#define FBT_RETURN	1
+
+typedef void *(*fbt_add_probe_fn)(struct module *, char *, int, int,
+				  asm_instr_t *, uintptr_t, void *, void *);
+extern void dtrace_fbt_init(fbt_add_probe_fn, struct module *, void *);
+
+/*
+ * Dynamic blacklist routines.
+ */
+struct dt_fbt_bl_entry;
+
+extern struct dt_fbt_bl_entry *dtrace_fbt_bl_add(unsigned long, const char *);
+extern struct dt_fbt_bl_entry *dtrace_fbt_bl_first(void);
+extern struct dt_fbt_bl_entry *dtrace_fbt_bl_next(struct dt_fbt_bl_entry *);
+extern unsigned long dtrace_fbt_bl_entry_addr(struct dt_fbt_bl_entry *);
+extern const char *dtrace_fbt_bl_entry_name(struct dt_fbt_bl_entry *);
+
+#endif /* _LINUX_DTRACE_FBT_H */
diff --git a/kernel/dtrace/Kconfig b/kernel/dtrace/Kconfig
index 6bf6620981cd..1f070e49c69f 100644
--- a/kernel/dtrace/Kconfig
+++ b/kernel/dtrace/Kconfig
@@ -55,6 +55,13 @@ config DT_SDT_PERF
 	  Provides the perf provider, containing a DTrace probe for each
 	  perf-events tracepoint in the system.
 
+config DT_FBT
+	tristate "Function boundary tracing"
+	default m
+	select FTRACE
+	help
+	  Provides function boundary tracing for functions in the kernel.
+
 config DT_SYSTRACE
 	tristate "System Call Tracing"
 	default m
diff --git a/kernel/dtrace/Makefile b/kernel/dtrace/Makefile
index 06329cbe52cb..0e5fb34b7b47 100644
--- a/kernel/dtrace/Makefile
+++ b/kernel/dtrace/Makefile
@@ -4,11 +4,11 @@
 
 DT_CORE_ARCH_OBJS		= $(addprefix ../../arch/$(SRCARCH)/kernel/, \
 				    dtrace_syscall.o dtrace_syscall_stubs.o \
-				    dtrace_sdt.o dtrace_util.o)
+				    dtrace_fbt.o dtrace_sdt.o dtrace_util.o)
 
 ifdef CONFIG_DT_CORE
 obj-y				+= cyclic.o dtrace_os.o dtrace_cpu.o \
-				   dtrace_sdt_core.o \
+				   dtrace_sdt_core.o dtrace_fbt_core.o \
 				   dtrace_task.o dtrace_psinfo.o \
 				   $(DT_CORE_ARCH_OBJS)
 endif
diff --git a/kernel/dtrace/dtrace_fbt_core.c b/kernel/dtrace/dtrace_fbt_core.c
new file mode 100644
index 000000000000..67182a3b13fc
--- /dev/null
+++ b/kernel/dtrace/dtrace_fbt_core.c
@@ -0,0 +1,125 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * FILE:        dtrace_fbt_core.c
+ * DESCRIPTION: DTrace - FBT common code
+ *
+ * Copyright (c) 2017, Oracle and/or its affiliates. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/kernel.h>
+#include <linux/kallsyms.h>
+#include <linux/rbtree.h>
+#include <linux/slab.h>
+#include <linux/dtrace_fbt.h>
+
+struct dt_fbt_bl_entry {
+	struct rb_node		dfbe_node;
+	unsigned long		dfbe_addr;
+	const char		*dfbe_name;
+};
+
+static struct rb_root dt_fbt_root = RB_ROOT;
+
+struct dt_fbt_bl_entry *
+dtrace_fbt_bl_add(unsigned long addr, const char *name)
+{
+	struct rb_node **p = &dt_fbt_root.rb_node;
+	struct rb_node *parent = NULL;
+	struct dt_fbt_bl_entry *entry;
+
+	/*
+	 * If no address was given, we need to do a symbol name lookup:
+	 *  - If no symbol name was given, we cannot add anything.
+	 *  - If the lookup failed, we cannot add anything.
+	 */
+	if (addr == 0) {
+		if (name == NULL)
+			return NULL;
+
+		addr = kallsyms_lookup_name(name);
+
+		if (addr == 0)
+			return NULL;
+	}
+
+	/* Find place in the tree. */
+	while (*p) {
+		parent = *p;
+		entry = rb_entry(parent, struct dt_fbt_bl_entry, dfbe_node);
+
+		if (addr > entry->dfbe_addr)
+			p = &parent->rb_right;
+		else if (addr < entry->dfbe_addr)
+			p = &parent->rb_left;
+		else
+			return NULL;		/* no duplicates please */
+	}
+
+	/* Create a new blacklist entry. */
+	entry = kmalloc(sizeof(*entry), GFP_KERNEL);
+	if (entry == NULL)
+		return NULL;
+
+	entry->dfbe_name = name;
+	entry->dfbe_addr = addr;
+
+	/* Update the tree. */
+	rb_link_node(&entry->dfbe_node, parent, p);
+	rb_insert_color(&entry->dfbe_node, &dt_fbt_root);
+
+	return entry;
+}
+
+/*
+ * Iterators for blacklisted symbols. The iteration happens in sort order by
+ * virtual memory address. Symbols with pending resolution are inored.
+ */
+struct dt_fbt_bl_entry *
+dtrace_fbt_bl_first(void)
+{
+	struct rb_node *node = rb_first(&dt_fbt_root);
+
+	if (node == NULL)
+		return (NULL);
+
+	return rb_entry(node, struct dt_fbt_bl_entry, dfbe_node);
+}
+
+struct dt_fbt_bl_entry *
+dtrace_fbt_bl_next(struct dt_fbt_bl_entry *entry)
+{
+	struct rb_node *node = rb_next(&entry->dfbe_node);
+
+	if (node == NULL)
+		return (NULL);
+
+	return rb_entry(node, struct dt_fbt_bl_entry, dfbe_node);
+}
+
+unsigned long
+dtrace_fbt_bl_entry_addr(struct dt_fbt_bl_entry *entry)
+{
+	if (entry == NULL)
+		return (0);
+
+	return entry->dfbe_addr;
+}
+
+const char *
+dtrace_fbt_bl_entry_name(struct dt_fbt_bl_entry *entry)
+{
+	if (entry == NULL)
+		return (NULL);
+
+	return entry->dfbe_name;
+}
diff --git a/kernel/dtrace/dtrace_os.c b/kernel/dtrace/dtrace_os.c
index 7140fd64cb7a..355bf1b6edc3 100644
--- a/kernel/dtrace/dtrace_os.c
+++ b/kernel/dtrace/dtrace_os.c
@@ -18,6 +18,7 @@
 
 #include <linux/binfmts.h>
 #include <linux/dtrace_cpu.h>
+#include <linux/dtrace_fbt.h>
 #include <linux/dtrace_os.h>
 #include <linux/dtrace_sdt.h>
 #include <linux/fs.h>
@@ -103,6 +104,7 @@ void __init dtrace_os_init(void)
 	dtrace_kmod->core_layout.size = 0x2000000;
 #endif
 
+	dtrace_kmod->num_ftrace_callsites = dtrace_fbt_nfuncs;
 	dtrace_kmod->state = MODULE_STATE_LIVE;
 	atomic_inc(&dtrace_kmod->refcnt);
 
diff --git a/kernel/kprobes.c b/kernel/kprobes.c
index 53534aa258a6..e2c0979a0f0a 100644
--- a/kernel/kprobes.c
+++ b/kernel/kprobes.c
@@ -36,6 +36,10 @@
 #include <linux/cpu.h>
 #include <linux/jump_label.h>
 
+#ifdef CONFIG_DTRACE
+#include <linux/dtrace_fbt.h>
+#endif
+
 #include <asm/sections.h>
 #include <asm/cacheflush.h>
 #include <asm/errno.h>
@@ -2131,6 +2135,10 @@ int kprobe_add_ksym_blacklist(unsigned long entry)
 	    !kallsyms_lookup_size_offset(entry, &size, &offset))
 		return -EINVAL;
 
+#ifdef CONFIG_DTRACE
+	dtrace_fbt_bl_add(entry, NULL);
+#endif
+
 	ent = kmalloc(sizeof(*ent), GFP_KERNEL);
 	if (!ent)
 		return -ENOMEM;
-- 
2.28.0

